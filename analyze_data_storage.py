import re
import json
from redis_utils import query_redis, set_redis, async_query_redis, async_set_redis

# åŸå§‹ Markdown æ•°æ®
markdown_data = "## ğŸš Plum 25R3.2 Sprint 2 : ORI-114277 æ•´ä½“è¿›å±•ç»¼è¿°\n> **å½“å‰çŠ¶æ€**: QA In Progress | **æ•´ä½“è¿›åº¦**: 4/11\n> **é£é™©æç¤º**: ğŸŸ  è¿›åº¦æ»å\n\n**ğŸ“ æœ€æ–°æƒ…å†µæ‘˜è¦**:\nStory ä¸»è¦ç ”å‘å·¥ä½œå·²å®Œæˆå¹¶è½¬å…¥æµ‹è¯•é˜¶æ®µã€‚è¿‡å»ä¸¤å¤©ï¼Œå¼€å‘äººå‘˜ Garry Peng é›†ä¸­å¤„ç†äº†ä¸‰ä¸ªç›¸å…³çš„å­ä»»åŠ¡/ç¼ºé™·ï¼Œå¹¶è®°å½•äº† 3.5 å°æ—¶å·¥æ—¶ï¼Œä¸»è¦è§£å†³äº†å¤šä¸ªå¯Œæ–‡æœ¬å­—æ®µåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„æ˜¾ç¤ºå’Œå€¼æ¸…ç©ºé—®é¢˜ã€‚QA è´Ÿè´£äºº Zijie Tang å·²å¼€å§‹ä»‹å…¥ï¼Œå¹¶è¦æ±‚æä¾›ç”¨äºPSä»£ç è‡ªå®šä¹‰é€»è¾‘çš„Demoæ•°æ®ã€‚\n\n---\n\n## ğŸ‘¥ å›¢é˜Ÿæˆå‘˜è¯¦ç»†åŠ¨æ€ (è¿‡å»ä¸¤å¤©)\n\n### ğŸ‘¤ Chuan Huang\n\n#### ğŸ”¹ ORI-136135 ã€adminã€‘longtext å­—æ®µåœ¨åˆå§‹æ‹–å…¥é¡µé¢æ—¶ï¼Œè®¾ç½®å…³è”å­—æ®µçš„å›ºå®šå€¼è¾“å…¥æ¡†ï¼Œæ²¡æœ‰å±•ç¤ºå¯Œæ–‡æœ¬æ ·å¼ ([ğŸ”µ task])\n* **2026-01-23**:\n    * **[Comment]** [~garry.peng@veeva.com] feature/ORI-136135/admin-affect-others-support-long-text\nä¸Šé¢åˆ†æ”¯åŠ ä¸Šäº†\n\n### ğŸ‘¤ Garry Peng\n\n#### ğŸ”¹ ORI-136183 ã€adminã€‘ longtext å­—æ®µä¸ºæ–‡æœ¬ç±»å‹æ—¶ï¼Œé…ç½®å­—æ®µå½±å“å…³ç³»é¡µé¢ï¼Œåœ¨å…³è”å­—æ®µé…ç½®å›ºå®šå€¼å¤„è¾“å…¥å¸¦æ ‡ç­¾çš„å†…å®¹ï¼Œåœ¨é¢„è§ˆé¡µé¢ä¼šå˜æˆå¯Œæ–‡æœ¬çš„æ ·å¼ ([ğŸ”µ task])\n* **2026-01-23**:\n    * **[Worklog 1h]** \n\n#### ğŸ”¹ ORI-136135 ã€adminã€‘longtext å­—æ®µåœ¨åˆå§‹æ‹–å…¥é¡µé¢æ—¶ï¼Œè®¾ç½®å…³è”å­—æ®µçš„å›ºå®šå€¼è¾“å…¥æ¡†ï¼Œæ²¡æœ‰å±•ç¤ºå¯Œæ–‡æœ¬æ ·å¼ ([ğŸ”µ task])\n* **2026-01-22**:\n    * **[Worklog 30m]** \n    * **[Comment]** /admin-api/object/\\{object_id}/page-layout/\\{layout_id}/ æ¥å£è¿”å›çš„ all_fields ä¸­çš„å­—æ®µä¹Ÿéœ€è¦å¸¦ä¸Š text_type [~chuan.huang@veeva.com]Â \n\n!image-2026-01-22-17-37-48-539.png!\n* **2026-01-23**:\n    * **[Worklog 1h]** \n\n#### ğŸ”¹ ORI-136130 ã€onlineã€‘ æ§åˆ¶å­—æ®µå°†longtext å­—æ®µ å¸¦å…¥å€¼åï¼Œå†å°†æ§åˆ¶å­—æ®µçš„å€¼æ¸…ç©ºï¼Œlongtext å­—æ®µçš„å€¼æœªæ¸…ç©º ([ğŸ”´ defect])\n* **2026-01-22**:\n    * **[Worklog 1h 30m]** \n\n### ğŸ‘¤ Zijie Tang\n\n#### ğŸ”¹ ORI-136130 ã€onlineã€‘ æ§åˆ¶å­—æ®µå°†longtext å­—æ®µ å¸¦å…¥å€¼åï¼Œå†å°†æ§åˆ¶å­—æ®µçš„å€¼æ¸…ç©ºï¼Œlongtext å­—æ®µçš„å€¼æœªæ¸…ç©º ([ğŸ”´ defect])\n* **2026-01-22**:\n    * **[Comment]** wechat ç«¯åŒæ ·å­˜åœ¨è¿™ä¸ªé—®é¢˜\n\n---\n*æ³¨ï¼šæŠ¥è¡¨ç”Ÿæˆæ—¶é—´ 2026-01-24*"


def parse_to_json(text, story_id):
    """
    è§£æMarkdownå¹¶å°†ç»“æœä¿å­˜/åˆå¹¶åˆ°æŒ‡å®šSprintå’ŒStoryçš„æ–‡ä»¶ä¸­ã€‚
    Sprint ID ä¼šä» text çš„ç¬¬ä¸€è¡Œæ ‡é¢˜ä¸­è‡ªåŠ¨æå–ã€‚
    """

    # ---------------------------------------------------------
    # 0. æå– Sprint ID
    # ---------------------------------------------------------
    sprint_match = re.search(r'^##\s+\S+\s+(.*?)\s*:', text, re.MULTILINE)

    if sprint_match:
        sprint_id = sprint_match.group(1).strip()
        print(f"æ£€æµ‹åˆ° Sprint ID: {sprint_id}")
    else:
        sprint_id = "Unknown_Sprint"
        print("Warning: æœªèƒ½ä»æ–‡æœ¬ä¸­æå– Sprint IDï¼Œä½¿ç”¨é»˜è®¤å€¼ã€‚")

    # ---------------------------------------------------------
    # 1. æå–å¹¶å­˜å‚¨â€œæœ€æ–°æƒ…å†µæ‘˜è¦â€
    # ---------------------------------------------------------
    summary_match = re.search(r'(\*\*ğŸ“ æœ€æ–°æƒ…å†µæ‘˜è¦\*\*:\n.*?)---', text, re.DOTALL)
    if summary_match:
        summary_content = summary_match.group(1).strip()
        summary_redis_key = f"story:summary:{story_id}"
        set_redis(summary_redis_key, summary_content)
        print(f"æˆåŠŸæå–â€œæœ€æ–°æƒ…å†µæ‘˜è¦â€å¹¶å­˜å…¥ Redis (Key: {summary_redis_key})ã€‚")
    else:
        print("Warning: æœªèƒ½åœ¨æ–‡æœ¬ä¸­æ‰¾åˆ°â€œæœ€æ–°æƒ…å†µæ‘˜è¦â€éƒ¨åˆ†ã€‚")

    # ---------------------------------------------------------
    # 2. æ ¸å¿ƒè§£æé€»è¾‘
    # ---------------------------------------------------------
    lines = text.split('\n')
    new_parsed_data = []

    current_user = None
    current_jira_id = None
    current_jira_title = None
    current_date = None

    re_user = re.compile(r'^###\s+ğŸ‘¤\s+(.+)')
    re_jira = re.compile(r'^####\s+ğŸ”¹\s+(ORI-\d+)\s+(.+)')

    # --- ä¿®æ”¹ç‚¹åœ¨è¿™é‡Œï¼šå»æ‰äº† regex ä¸­çš„ \[ å’Œ \] ---
    # åŸå§‹: r'^\*\s+\*\*\[(\d{4}-\d{2}-\d{2})\]\*\*: '
    # ä¿®æ”¹å: r'^\*\s+\*\*(\d{4}-\d{2}-\d{2})\*\*: '
    re_date = re.compile(r'^\*\s+\*\*(\d{4}-\d{2}-\d{2})\*\*:')

    re_item = re.compile(r'^\s+\*\s+(\*\*\[.*?\]\*\*)\s*(.*)')

    for line in lines:
        line = line.rstrip()
        user_match = re_user.match(line)
        if user_match:
            current_user = user_match.group(1).strip()
            continue

        jira_match = re_jira.match(line)
        if jira_match:
            current_jira_id = jira_match.group(1).strip()
            current_jira_title = jira_match.group(2).strip()
            continue

        date_match = re_date.match(line.strip())
        if date_match:
            current_date = date_match.group(1).strip()
            continue

        item_match = re_item.match(line)
        if item_match:
            tag_part = item_match.group(1)
            text_part = item_match.group(2)

            if current_user and current_jira_id and current_date:
                new_parsed_data.append({
                    "User": current_user,
                    "Jira_ID": current_jira_id,
                    "Jira_Title": current_jira_title,
                    "Date": current_date,
                    "Content": tag_part,
                    "Comment": text_part.strip()
                })

    # ---------------------------------------------------------
    # 3. Redis æ“ä½œé€»è¾‘
    # ---------------------------------------------------------

    # æ„é€  Redis Key, æ ¼å¼: story:personal_progress:{story_id}
    redis_key = f"story:personal_progress:{story_id}"

    # ä» Redis è¯»å–ç°æœ‰æ•°æ®
    existing_data = query_redis('GET', redis_key)
    if not isinstance(existing_data, list):
        final_data = []
    else:
        final_data = existing_data
    
    print(f"ä» Redis (Key: {redis_key}) è¯»å–äº† {len(final_data)} æ¡å·²æœ‰æ•°æ®ã€‚")

    # æ•°æ®æ¸…ç†ä¸åˆå¹¶é€»è¾‘
    
    # 1. æ¸…ç† Redis ä¸­çš„ç°æœ‰è„æ•°æ®ï¼ˆå»é‡ï¼‰
    initial_count = len(final_data)
    
    # ä½¿ç”¨å­—å…¸å»é‡ï¼Œä¿ç•™æ¯ä¸ªå¤åˆé”®æœ€åå‡ºç°çš„å…ƒç´ ã€‚
    # è¿™ä¸€æ­¥åŒæ—¶ä¹Ÿä¸ºåç»­åˆå¹¶ new_parsed_data å‡†å¤‡äº† existing_mapã€‚
    existing_map = {
        (item.get('User'), item.get('Jira_ID'), item.get('Date')): item
        for item in final_data if isinstance(item, dict) and all(item.get(k) for k in ['User', 'Jira_ID', 'Date'])
    }
    final_data = list(existing_map.values())
    
    cleaned_count = len(final_data)
    if initial_count > cleaned_count:
        print(f"æ•°æ®æ¸…ç†ï¼šæ£€æµ‹åˆ°å¹¶ç§»é™¤äº† {initial_count - cleaned_count} æ¡é‡å¤çš„ç°æœ‰è®°å½•ã€‚")

    # 2. å°†æ–°è§£æçš„æ•°æ®åˆå¹¶åˆ°å·²æ¸…ç†çš„æ•°æ®ä¸­
    update_count = 0
    append_count = 0

    for new_item in new_parsed_data:
        # ç¡®ä¿ new_item æ ¼å¼æ­£ç¡®
        if not (isinstance(new_item, dict) and all(new_item.get(k) for k in ['User', 'Jira_ID', 'Date'])):
            continue
            
        key = (new_item['User'], new_item['Jira_ID'], new_item['Date'])
        existing_item = existing_map.get(key)

        if existing_item:
            # é”®å­˜åœ¨ï¼Œæ›´æ–°
            if existing_item.get('Content') != new_item.get('Content') or existing_item.get('Comment') != new_item.get('Comment'):
                existing_item.update(new_item)
                update_count += 1
        else:
            # é”®ä¸å­˜åœ¨ï¼Œæ–°å¢
            final_data.append(new_item)
            existing_map[key] = new_item
            append_count += 1

    # 3. ç»“æœå†™å›
    # åªè¦æœ‰ä»»ä½•å˜åŠ¨ï¼ˆæ¸…ç†ã€æ–°å¢ã€æ›´æ–°ï¼‰ï¼Œå°±æ‰§è¡Œå†™å›æ“ä½œ
    if initial_count != cleaned_count or append_count > 0 or update_count > 0:
        if append_count > 0:
            print(f"æˆåŠŸè¿½åŠ  {append_count} æ¡æ–°è®°å½•ã€‚")
        if update_count > 0:
            print(f"æˆåŠŸæ›´æ–° {update_count} æ¡ç°æœ‰è®°å½•ã€‚")
        
        set_redis(redis_key, final_data)
        print(f"æ•°æ®å·²å†™å› Redis (Key: {redis_key})ã€‚")
    else:
        print("æ— éœ€æ”¹åŠ¨ï¼šæ•°æ®å·²æ˜¯æœ€æ–°ä¸”æ— é‡å¤ã€‚")

    return final_data


async def async_parse_to_json(text, story_id):
    """
    å¼‚æ­¥è§£æMarkdownå¹¶å°†ç»“æœä¿å­˜/åˆå¹¶åˆ°æŒ‡å®šSprintå’ŒStoryçš„æ–‡ä»¶ä¸­ã€‚
    """
    sprint_match = re.search(r'^##\s+\S+\s+(.*?)\s*:', text, re.MULTILINE)

    if sprint_match:
        sprint_id = sprint_match.group(1).strip()
    else:
        sprint_id = "Unknown_Sprint"

    summary_match = re.search(r'(\*\*ğŸ“ æœ€æ–°æƒ…å†µæ‘˜è¦\*\*:\n.*?)---', text, re.DOTALL)
    if summary_match:
        summary_content = summary_match.group(1).strip()
        summary_redis_key = f"story:summary:{story_id}"
        await async_set_redis(summary_redis_key, summary_content)

    lines = text.split('\n')
    new_parsed_data = []
    current_user = None
    current_jira_id = None
    current_jira_title = None
    current_date = None

    re_user = re.compile(r'^###\s+ğŸ‘¤\s+(.+)')
    re_jira = re.compile(r'^####\s+ğŸ”¹\s+(ORI-\d+)\s+(.+)')
    re_date = re.compile(r'^\*\s+\*\*(\d{4}-\d{2}-\d{2})\*\*:')
    re_item = re.compile(r'^\s+\*\s+(\*\*\[.*?\]\*\*)\s*(.*)')

    for line in lines:
        line = line.rstrip()
        user_match = re_user.match(line)
        if user_match:
            current_user = user_match.group(1).strip()
            continue
        jira_match = re_jira.match(line)
        if jira_match:
            current_jira_id = jira_match.group(1).strip()
            current_jira_title = jira_match.group(2).strip()
            continue
        date_match = re_date.match(line.strip())
        if date_match:
            current_date = date_match.group(1).strip()
            continue
        item_match = re_item.match(line)
        if item_match:
            tag_part = item_match.group(1)
            text_part = item_match.group(2)
            if current_user and current_jira_id and current_date:
                new_parsed_data.append({
                    "User": current_user,
                    "Jira_ID": current_jira_id,
                    "Jira_Title": current_jira_title,
                    "Date": current_date,
                    "Content": tag_part,
                    "Comment": text_part.strip()
                })

    redis_key = f"story:personal_progress:{story_id}"
    existing_data = await async_query_redis('GET', redis_key)
    
    if not isinstance(existing_data, list):
        final_data = []
    else:
        final_data = existing_data

    existing_map = {
        (item.get('User'), item.get('Jira_ID'), item.get('Date')): item
        for item in final_data if isinstance(item, dict) and all(item.get(k) for k in ['User', 'Jira_ID', 'Date'])
    }
    
    update_count = 0
    append_count = 0

    for new_item in new_parsed_data:
        if not (isinstance(new_item, dict) and all(new_item.get(k) for k in ['User', 'Jira_ID', 'Date'])):
            continue
        key = (new_item['User'], new_item['Jira_ID'], new_item['Date'])
        existing_item = existing_map.get(key)
        if existing_item:
            if existing_item.get('Content') != new_item.get('Content') or existing_item.get('Comment') != new_item.get('Comment'):
                existing_item.update(new_item)
                update_count += 1
        else:
            final_data.append(new_item)
            existing_map[key] = new_item
            append_count += 1

    if len(existing_data) != len(final_data) or append_count > 0 or update_count > 0:
        await async_set_redis(redis_key, final_data)

    return final_data


def get_story_description(story_id):
    # 1. Get personal progress data
    personal_progress_key = f"story:personal_progress:{story_id}"
    personal_process_data = query_redis('GET', personal_progress_key)

    # 2. Get tags data
    tags_key = f"story:tags:{story_id}"
    tags_data = query_redis('GET', tags_key)

    # 3. Get summary data
    summary_key = f"story:summary:{story_id}"
    summary_data = query_redis('GET', summary_key)

    # If all are missing, return an error
    if not personal_process_data and not tags_data and not summary_data:
        return {"error": f"åœ¨ Redis ä¸­æœªæ‰¾åˆ° story '{story_id}' çš„ä»»ä½•ç›¸å…³æ•°æ®ï¼ˆè¿›åº¦ã€æ ‡ç­¾æˆ–ç»¼è¿°ï¼‰ã€‚"}

    # 4. Combine into the final dictionary
    result = {
        "summary": summary_data if summary_data else "",
        "tags": tags_data if tags_data else [],
        "personal_process_data": personal_process_data if personal_process_data else []
    }

    return result


async def async_get_story_description(story_id):
    # 1. Get personal progress data
    personal_progress_key = f"story:personal_progress:{story_id}"
    personal_process_data = await async_query_redis('GET', personal_progress_key)

    # 2. Get tags data
    tags_key = f"story:tags:{story_id}"
    tags_data = await async_query_redis('GET', tags_key)

    # 3. Get summary data
    summary_key = f"story:summary:{story_id}"
    summary_data = await async_query_redis('GET', summary_key)

    # If all are missing, return an error
    if not personal_process_data and not tags_data and not summary_data:
        return {"error": f"åœ¨ Redis ä¸­æœªæ‰¾åˆ° story '{story_id}' çš„ä»»ä½•ç›¸å…³æ•°æ®ï¼ˆè¿›åº¦ã€æ ‡ç­¾æˆ–ç»¼è¿°ï¼‰ã€‚"}

    # 4. Combine into the final dictionary
    result = {
        "summary": summary_data if summary_data else "",
        "tags": tags_data if tags_data else [],
        "personal_process_data": personal_process_data if personal_process_data else []
    }

    return result


# --- æµ‹è¯•è°ƒç”¨ ---
if __name__ == "__main__":
    try:
        result = parse_to_json(markdown_data, story_id="ORI-114277")
        print(f"\næœ€ç»ˆæ•°æ®æ¡æ•°: {len(result)}")
        if len(result) > 0:
            print("é¢„è§ˆç¬¬ä¸€æ¡æ•°æ®:")
            print(json.dumps(result[:1], indent=2, ensure_ascii=False))
        else:
            print("è­¦å‘Š: ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥ Regex åŒ¹é…é€»è¾‘ã€‚")
        
        print("\n--- Testing story_description ---")
        story_data = get_story_description("ORI-114277")
        print(json.dumps(story_data, indent=2, ensure_ascii=False))

        story_data_not_found = get_story_description("ORI-000000")
        print(json.dumps(story_data_not_found, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"\næ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
