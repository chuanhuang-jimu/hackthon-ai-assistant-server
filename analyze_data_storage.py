import re
import json
import os

# åŸå§‹ Markdown æ•°æ®
markdown_data = "## ğŸš Plum 25R3.2 Sprint 2 : ORI-114277 æ•´ä½“è¿›å±•ç»¼è¿°\n> **å½“å‰çŠ¶æ€**: QA In Progress | **æ•´ä½“è¿›åº¦**: 4/11\n> **é£é™©æç¤º**: ğŸŸ  è¿›åº¦æ»å\n\n**ğŸ“ æœ€æ–°æƒ…å†µæ‘˜è¦**:\nStory ä¸»è¦ç ”å‘å·¥ä½œå·²å®Œæˆå¹¶è½¬å…¥æµ‹è¯•é˜¶æ®µã€‚è¿‡å»ä¸¤å¤©ï¼Œå¼€å‘äººå‘˜ Garry Peng é›†ä¸­å¤„ç†äº†ä¸‰ä¸ªç›¸å…³çš„å­ä»»åŠ¡/ç¼ºé™·ï¼Œå¹¶è®°å½•äº† 3.5 å°æ—¶å·¥æ—¶ï¼Œä¸»è¦è§£å†³äº†å¤šä¸ªå¯Œæ–‡æœ¬å­—æ®µåœ¨ç‰¹å®šåœºæ™¯ä¸‹çš„æ˜¾ç¤ºå’Œå€¼æ¸…ç©ºé—®é¢˜ã€‚QA è´Ÿè´£äºº Zijie Tang å·²å¼€å§‹ä»‹å…¥ï¼Œå¹¶è¦æ±‚æä¾›ç”¨äºPSä»£ç è‡ªå®šä¹‰é€»è¾‘çš„Demoæ•°æ®ã€‚\n\n---\n\n## ğŸ‘¥ å›¢é˜Ÿæˆå‘˜è¯¦ç»†åŠ¨æ€ (è¿‡å»ä¸¤å¤©)\n\n### ğŸ‘¤ Chuan Huang\n\n#### ğŸ”¹ ORI-136135 ã€adminã€‘longtext å­—æ®µåœ¨åˆå§‹æ‹–å…¥é¡µé¢æ—¶ï¼Œè®¾ç½®å…³è”å­—æ®µçš„å›ºå®šå€¼è¾“å…¥æ¡†ï¼Œæ²¡æœ‰å±•ç¤ºå¯Œæ–‡æœ¬æ ·å¼ ([ğŸ”µ task])\n* **2026-01-23**:\n    * **[Comment]** [~garry.peng@veeva.com] feature/ORI-136135/admin-affect-others-support-long-text\nä¸Šé¢åˆ†æ”¯åŠ ä¸Šäº†\n\n### ğŸ‘¤ Garry Peng\n\n#### ğŸ”¹ ORI-136183 ã€adminã€‘ longtext å­—æ®µä¸ºæ–‡æœ¬ç±»å‹æ—¶ï¼Œé…ç½®å­—æ®µå½±å“å…³ç³»é¡µé¢ï¼Œåœ¨å…³è”å­—æ®µé…ç½®å›ºå®šå€¼å¤„è¾“å…¥å¸¦æ ‡ç­¾çš„å†…å®¹ï¼Œåœ¨é¢„è§ˆé¡µé¢ä¼šå˜æˆå¯Œæ–‡æœ¬çš„æ ·å¼ ([ğŸ”µ task])\n* **2026-01-23**:\n    * **[Worklog 1h]** \n\n#### ğŸ”¹ ORI-136135 ã€adminã€‘longtext å­—æ®µåœ¨åˆå§‹æ‹–å…¥é¡µé¢æ—¶ï¼Œè®¾ç½®å…³è”å­—æ®µçš„å›ºå®šå€¼è¾“å…¥æ¡†ï¼Œæ²¡æœ‰å±•ç¤ºå¯Œæ–‡æœ¬æ ·å¼ ([ğŸ”µ task])\n* **2026-01-22**:\n    * **[Worklog 30m]** \n    * **[Comment]** /admin-api/object/\\{object_id}/page-layout/\\{layout_id}/ æ¥å£è¿”å›çš„ all_fields ä¸­çš„å­—æ®µä¹Ÿéœ€è¦å¸¦ä¸Š text_type [~chuan.huang@veeva.com]Â \n\n!image-2026-01-22-17-37-48-539.png!\n* **2026-01-23**:\n    * **[Worklog 1h]** \n\n#### ğŸ”¹ ORI-136130 ã€onlineã€‘ æ§åˆ¶å­—æ®µå°†longtext å­—æ®µ å¸¦å…¥å€¼åï¼Œå†å°†æ§åˆ¶å­—æ®µçš„å€¼æ¸…ç©ºï¼Œlongtext å­—æ®µçš„å€¼æœªæ¸…ç©º ([ğŸ”´ defect])\n* **2026-01-22**:\n    * **[Worklog 1h 30m]** \n\n### ğŸ‘¤ Zijie Tang\n\n#### ğŸ”¹ ORI-136130 ã€onlineã€‘ æ§åˆ¶å­—æ®µå°†longtext å­—æ®µ å¸¦å…¥å€¼åï¼Œå†å°†æ§åˆ¶å­—æ®µçš„å€¼æ¸…ç©ºï¼Œlongtext å­—æ®µçš„å€¼æœªæ¸…ç©º ([ğŸ”´ defect])\n* **2026-01-22**:\n    * **[Comment]** wechat ç«¯åŒæ ·å­˜åœ¨è¿™ä¸ªé—®é¢˜\n\n---\n*æ³¨ï¼šæŠ¥è¡¨ç”Ÿæˆæ—¶é—´ 2026-01-24*"


def parse_to_json(text, story_id):
    """
    è§£æMarkdownå¹¶å°†ç»“æœä¿å­˜/åˆå¹¶åˆ°æŒ‡å®šSprintå’ŒStoryçš„æ–‡ä»¶ä¸­ã€‚
    Sprint ID ä¼šä» text çš„ç¬¬ä¸€è¡Œæ ‡é¢˜ä¸­è‡ªåŠ¨æå–ã€‚
    """

    # ---------------------------------------------------------
    # 0. æå– Sprint ID
    # ---------------------------------------------------------
    sprint_match = re.search(r'^##\s+\S+\s+(.*?)\s*:', text, re.MULTILINE)

    if sprint_match:
        sprint_id = sprint_match.group(1).strip()
        print(f"æ£€æµ‹åˆ° Sprint ID: {sprint_id}")
    else:
        sprint_id = "Unknown_Sprint"
        print("Warning: æœªèƒ½ä»æ–‡æœ¬ä¸­æå– Sprint IDï¼Œä½¿ç”¨é»˜è®¤å€¼ã€‚")

    # ---------------------------------------------------------
    # 1. æ ¸å¿ƒè§£æé€»è¾‘
    # ---------------------------------------------------------
    lines = text.split('\n')
    new_parsed_data = []

    current_user = None
    current_jira_id = None
    current_jira_title = None
    current_date = None

    re_user = re.compile(r'^###\s+ğŸ‘¤\s+(.+)')
    re_jira = re.compile(r'^####\s+ğŸ”¹\s+(ORI-\d+)\s+(.+)')

    # --- ä¿®æ”¹ç‚¹åœ¨è¿™é‡Œï¼šå»æ‰äº† regex ä¸­çš„ \[ å’Œ \] ---
    # åŸå§‹: r'^\*\s+\*\*\[(\d{4}-\d{2}-\d{2})\]\*\*: '
    # ä¿®æ”¹å: r'^\*\s+\*\*(\d{4}-\d{2}-\d{2})\*\*: '
    re_date = re.compile(r'^\*\s+\*\*(\d{4}-\d{2}-\d{2})\*\*:')

    re_item = re.compile(r'^\s+\*\s+(\*\*\[.*?\]\*\*)\s*(.*)')

    for line in lines:
        line = line.rstrip()
        user_match = re_user.match(line)
        if user_match:
            current_user = user_match.group(1).strip()
            continue

        jira_match = re_jira.match(line)
        if jira_match:
            current_jira_id = jira_match.group(1).strip()
            current_jira_title = jira_match.group(2).strip()
            continue

        date_match = re_date.match(line.strip())
        if date_match:
            current_date = date_match.group(1).strip()
            continue

        item_match = re_item.match(line)
        if item_match:
            tag_part = item_match.group(1)
            text_part = item_match.group(2)

            if current_user and current_jira_id and current_date:
                new_parsed_data.append({
                    "User": current_user,
                    "Jira_ID": current_jira_id,
                    "Jira_Title": current_jira_title,
                    "Date": current_date,
                    "Content": tag_part,
                    "Comment": text_part.strip()
                })

    # ---------------------------------------------------------
    # 2. æ–‡ä»¶ç³»ç»Ÿæ“ä½œé€»è¾‘
    # ---------------------------------------------------------

    base_dir = "/Users/ChuanHuang/Desktop/project/hackathon-personal-assistant/analyze_data"
    sprint_dir = os.path.join(base_dir, sprint_id)

    if not os.path.exists(sprint_dir):
        print(f"æ–‡ä»¶å¤¹ä¸å­˜åœ¨ï¼Œæ­£åœ¨åˆ›å»º: {sprint_dir}")
        os.makedirs(sprint_dir, exist_ok=True)

    json_file_path = os.path.join(sprint_dir, f"{story_id}.json")

    final_data = []

    if os.path.exists(json_file_path):
        print(f"å‘ç°å·²æœ‰æ–‡ä»¶ï¼Œæ­£åœ¨è¯»å–åˆå¹¶: {json_file_path}")
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                existing_data = json.load(f)
                if isinstance(existing_data, list):
                    final_data = existing_data
                else:
                    final_data = []
        except Exception as e:
            print(f"è¯»å–æ—§æ–‡ä»¶å‡ºé”™: {e}, å°†è¦†ç›–é‡å†™ã€‚")
            final_data = []
    else:
        print(f"æ–‡ä»¶ä¸å­˜åœ¨ï¼Œå°†åˆ›å»ºæ–°æ–‡ä»¶: {json_file_path}")

    # æ•°æ®è¿½åŠ é€»è¾‘
    append_count = 0
    # ä¸ºäº†å¯¹æ¯”å»é‡ï¼Œæˆ‘ä»¬å°† new_item ä¸ final_data ä¸­çš„æ¯ä¸€é¡¹è¿›è¡Œå¯¹æ¯”
    # æ³¨æ„ï¼šå­—å…¸æ¯”è¾ƒé¡ºåºæ— å…³ï¼Œä½†å†…å®¹å¿…é¡»å®Œå…¨ä¸€è‡´
    for new_item in new_parsed_data:
        if new_item not in final_data:
            final_data.append(new_item)
            append_count += 1

    if append_count > 0:
        print(f"æˆåŠŸè¿½åŠ  {append_count} æ¡æ–°è®°å½•ã€‚")
    else:
        print("æ²¡æœ‰æ–°è®°å½•éœ€è¦è¿½åŠ ï¼ˆæ•°æ®å·²å­˜åœ¨ æˆ– è§£æç»“æœä¸ºç©ºï¼‰ã€‚")

    # å†™å…¥æœ€ç»ˆç»“æœ
    with open(json_file_path, 'w', encoding='utf-8') as f:
        json.dump(final_data, f, indent=2, ensure_ascii=False)

    return final_data


def get_story_description(sprint_name, story_id):
    base_dir = "/Users/ChuanHuang/Desktop/project/hackathon-personal-assistant/analyze_data"
    sprint_path = os.path.join(base_dir, sprint_name)
    if not os.path.isdir(sprint_path):
        return {"error": "sprintæœªå®Œæˆåˆ†æ"}

    story_file_path = os.path.join(sprint_path, f"{story_id}.json")
    if not os.path.isfile(story_file_path):
        return {"error": "storyæœªå®Œæˆåˆ†æ"}

    with open(story_file_path, 'r', encoding='utf-8') as f:
        data = json.load(f)

    return data


# --- æµ‹è¯•è°ƒç”¨ ---
if __name__ == "__main__":
    try:
        result = parse_to_json(markdown_data, story_id="ORI-114277")
        print(f"\næœ€ç»ˆæ•°æ®æ¡æ•°: {len(result)}")
        if len(result) > 0:
            print("é¢„è§ˆç¬¬ä¸€æ¡æ•°æ®:")
            print(json.dumps(result[:1], indent=2, ensure_ascii=False))
        else:
            print("è­¦å‘Š: ç»“æœä¸ºç©ºï¼Œè¯·æ£€æŸ¥ Regex åŒ¹é…é€»è¾‘ã€‚")
        
        print("\n--- Testing story_description ---")
        story_data = story_description("Plum 25R3.2 Sprint 2", "ORI-114277")
        print(json.dumps(story_data, indent=2, ensure_ascii=False))

        story_data_not_found = story_description("Plum 25R3.2 Sprint 2", "ORI-000000")
        print(json.dumps(story_data_not_found, indent=2, ensure_ascii=False))

        sprint_not_found = story_description("Unknown Sprint", "ORI-114277")
        print(json.dumps(sprint_not_found, indent=2, ensure_ascii=False))

    except Exception as e:
        print(f"\næ‰§è¡Œè¿‡ç¨‹ä¸­é‡åˆ°é”™è¯¯: {e}")
